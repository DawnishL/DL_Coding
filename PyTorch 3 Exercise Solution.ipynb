{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c10659b-c923-4108-932d-0110be5a11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset as LDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4176cee6-6ac1-426f-b0d3-7417a8bfd1b4",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c6e382-0130-4f72-8255-4dd236a2d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LDataset.from_csv(\"https://www.kaggle.com/api/v1/datasets/download/camnugent/california-housing-prices\", cache_dir=\"/scratch/singh/hf/datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c08c20-1ac8-441a-8411-046c9cefbb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value', 'ocean_proximity'],\n",
       "    num_rows: 20640\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81fec073-1d7a-489e-a232-68bf7d8ca674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'longitude': -122.22,\n",
       " 'latitude': 37.86,\n",
       " 'housing_median_age': 21.0,\n",
       " 'total_rooms': 7099.0,\n",
       " 'total_bedrooms': 1106.0,\n",
       " 'population': 2401.0,\n",
       " 'households': 1138.0,\n",
       " 'median_income': 8.3014,\n",
       " 'median_house_value': 358500.0,\n",
       " 'ocean_proximity': 'NEAR BAY'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92647a55-9f9a-4667-8e9b-4caa901aa448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value', 'ocean_proximity'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488bf943-ba4c-4bbd-876f-4d6aaaddc1bc",
   "metadata": {},
   "source": [
    "#### Separating Numerical Featuress and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdf7af3-ff33-45a6-8029-be0948d04663",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "865f06c3-f7b8-42bb-a595-a269dde10bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26480538-7f3b-4654-9f16-90f45d85f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'median_house_value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "870ef2a0-f6e1-42b4-b088-07defaad8375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for idx, row in enumerate(dataset):\n",
    "#     if any(elem is None for elem in list(row.values())):\n",
    "#         print(row)\n",
    "#         print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9ac900c-e1d1-48ee-8263-5613ed887256",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list()\n",
    "targets = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b7aba-3691-43b0-9088-b5b0aab0f51b",
   "metadata": {},
   "source": [
    "##### Total Bedrooms has None values, dealing with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af00d540-34d6-42b6-b345-3ca8009fa67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_total_bedrooms = 0\n",
    "count_valid_rows = 0\n",
    "for row in dataset:\n",
    "    if row[\"total_bedrooms\"]:\n",
    "        sum_total_bedrooms += row[\"total_bedrooms\"]\n",
    "        count_valid_rows += 1\n",
    "mean_total_bedrooms = sum_total_bedrooms/count_valid_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10c7eee5-ba75-4461-9b3e-6ecd6c078acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537.8705525375618"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_total_bedrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57972afd-1d26-4cfb-b8da-9e0e6fe970cb",
   "metadata": {},
   "source": [
    "Now, let's collect all the numerical features into a single list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95c1a2e2-f4fd-4a8f-9e22-2d51d78dfe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in dataset:\n",
    "    feature_values = list()\n",
    "    for feat in numerical_features:\n",
    "        if feat == \"total_bedrooms\":\n",
    "            if row[feat]:\n",
    "                feature_values.append(row[feat])\n",
    "            else:\n",
    "                feature_values.append(mean_total_bedrooms)\n",
    "        else:\n",
    "            feature_values.append(row[feat])\n",
    "    features.append(feature_values)\n",
    "    targets.append(row[target_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecd22102-489c-48cc-97d0-39ebe2e9da85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-122.23, 37.88, 41.0, 880.0, 129.0, 322.0, 126.0, 8.3252]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67c1fb6b-e507-4ce9-b72f-e8c830432811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452600.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae5256d-04ca-4425-9231-4d91576c95a6",
   "metadata": {},
   "source": [
    "#### Now we need to handle the categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bb20761-e33f-423a-a827-b4c8cd658491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NEAR BAY', 'NEAR BAY', 'NEAR BAY', 'NEAR BAY', 'NEAR BAY']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocean_proximity = [row['ocean_proximity'] for row in dataset]\n",
    "ocean_proximity[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da68ccd4-08fd-4416-8e02-31f385a8d569",
   "metadata": {},
   "source": [
    "##### Let's look into what are the unique categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18f16b17-ed9a-4d0c-9096-4dd36b6dc2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ISLAND', 'NEAR OCEAN', '<1H OCEAN', 'NEAR BAY', 'INLAND']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_categories = list(set(ocean_proximity))\n",
    "unique_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb552adf-c8ad-4c5d-990e-e942c58dfd6b",
   "metadata": {},
   "source": [
    "##### Let's create a mapping from the category to the index for the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ec6dce8-a08a-40f2-829f-91ecf30656d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_onehot = dict()\n",
    "for idx, category in enumerate(unique_categories):\n",
    "    category_to_onehot[category] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a739251-3a2c-4637-842f-68e9564ffa9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ISLAND': 0, 'NEAR OCEAN': 1, '<1H OCEAN': 2, 'NEAR BAY': 3, 'INLAND': 4}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_to_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eeb8df-df81-43d5-8119-73bd901a62e8",
   "metadata": {},
   "source": [
    "##### Creating One hot encoded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ff682b4-cd00-447b-abda-8aecea3c71b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_vectors = torch.eye(len(unique_categories))\n",
    "onehot_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5e5e4b-130b-49a3-8b4f-b39df14f0ed7",
   "metadata": {},
   "source": [
    "##### Now, for all the values of ocean_proximity, we can add the respective one hot encoded vector for it in the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f74ece2-2c4e-4390-99e6-512bb0f1dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, category in enumerate(ocean_proximity):\n",
    "    features[i].extend(onehot_vectors[category_to_onehot[category]].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb1ecf07-4b04-4ae4-b7ef-7ac7deedf739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-122.16,\n",
       " 37.77,\n",
       " 47.0,\n",
       " 1256.0,\n",
       " 537.8705525375618,\n",
       " 570.0,\n",
       " 218.0,\n",
       " 4.375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[290]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531f0525-3614-4e05-a64a-b360f3b02517",
   "metadata": {},
   "source": [
    "##### Finally, we will convert these into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86cc92c5-364e-4dcf-a628-fa330f9c2fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(features, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c155856-a7e1-4034-b4fa-8cc4d2465725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-122.2300,   37.8800,   41.0000,  ...,    0.0000,    1.0000,\n",
       "            0.0000],\n",
       "        [-122.2200,   37.8600,   21.0000,  ...,    0.0000,    1.0000,\n",
       "            0.0000],\n",
       "        [-122.2400,   37.8500,   52.0000,  ...,    0.0000,    1.0000,\n",
       "            0.0000],\n",
       "        ...,\n",
       "        [-121.2200,   39.4300,   17.0000,  ...,    0.0000,    0.0000,\n",
       "            1.0000],\n",
       "        [-121.3200,   39.4300,   18.0000,  ...,    0.0000,    0.0000,\n",
       "            1.0000],\n",
       "        [-121.2400,   39.3700,   16.0000,  ...,    0.0000,    0.0000,\n",
       "            1.0000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f83046e9-96df-4bc7-8b02-11b75f7427f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[452600.],\n",
       "        [358500.],\n",
       "        [352100.],\n",
       "        ...,\n",
       "        [ 92300.],\n",
       "        [ 84700.],\n",
       "        [ 89400.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor(targets, dtype=torch.float32).view(-1, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765a1677-0723-4493-bff8-a305d48727a2",
   "metadata": {},
   "source": [
    "#### The final part for the preprocessing is the normalization of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afe1355d-9ebd-4213-aaca-b1989851e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 8 columns are the numerical features, \n",
    "# last 5 are the one hot encoded features for ocean_proximity\n",
    "numeric_features = X[:, :8] \n",
    "# We are calculating mean and the standard deviation \n",
    "# of the numerical features so that we can normalize them\n",
    "numeric_means = numeric_features.mean(dim=0, keepdim=True)\n",
    "numeric_stds = numeric_features.std(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df47235f-806f-406f-97eb-76d2e64f0277",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, :8] = (numeric_features - numeric_means) / numeric_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c7d33b1-f789-42d0-bdd0-1164728f5c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3278,  1.0525,  0.9821,  ...,  0.0000,  1.0000,  0.0000],\n",
       "        [-1.3228,  1.0432, -0.6070,  ...,  0.0000,  1.0000,  0.0000],\n",
       "        [-1.3328,  1.0385,  1.8561,  ...,  0.0000,  1.0000,  0.0000],\n",
       "        ...,\n",
       "        [-0.8237,  1.7782, -0.9248,  ...,  0.0000,  0.0000,  1.0000],\n",
       "        [-0.8736,  1.7782, -0.8454,  ...,  0.0000,  0.0000,  1.0000],\n",
       "        [-0.8337,  1.7501, -1.0043,  ...,  0.0000,  0.0000,  1.0000]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e931d6-9c2f-4925-8832-293f923d57f1",
   "metadata": {},
   "source": [
    "#### Preparing dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30dfa419-1471-49ac-b3eb-b8384bcaf02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fc9ef94-8b4e-427e-95da-2ec6d2bba116",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a286949-05d3-400f-9838-288449051c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom PyTorch dataset\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f54d376-ce92-4505-8977-c4554f6c49b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_262395/3886441515.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_dataset = RegressionDataset(torch.tensor(X_train, dtype=torch.float32),\n",
      "/tmp/ipykernel_262395/3886441515.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y_train, dtype=torch.float32))\n",
      "/tmp/ipykernel_262395/3886441515.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_dataset = RegressionDataset(torch.tensor(X_val, dtype=torch.float32),\n",
      "/tmp/ipykernel_262395/3886441515.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y_val, dtype=torch.float32))\n"
     ]
    }
   ],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = RegressionDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                   torch.tensor(y_train, dtype=torch.float32))\n",
    "val_dataset = RegressionDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                                 torch.tensor(y_val, dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36439600-59d9-41ef-bf8a-9a42014bea0a",
   "metadata": {},
   "source": [
    "#### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d2c60cf-9b5c-476e-843f-e568709e7279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 256)  # Single layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06c8bcea-2687-4763-8eb2-6499587a2e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70fe7c47-3c5a-417b-9a05-10ec406c876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel(input_dim=X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c934fd1-abfa-4288-b9f3-0ff55ee240d7",
   "metadata": {},
   "source": [
    "#### Training with GPU and Model Checkpoint Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ca7a3ee-14d8-4a29-97cb-e63d14ea9163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (layer1): Linear(in_features=13, out_features=256, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (layer2): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1df01385-bf93-4770-ac7b-5c5a6b7e0931",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "checkpoint_path = \"best_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cacfe28d-14bd-4b4e-af85-baab52905605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 55966081889.2403, Val Loss: 56631219096.8062\n",
      "Epoch 2/5, Train Loss: 55951132691.8450, Val Loss: 56611042089.6744\n",
      "Epoch 3/5, Train Loss: 55925605364.0930, Val Loss: 56579500428.8992\n",
      "Epoch 4/5, Train Loss: 55888397236.5891, Val Loss: 56536265116.7752\n",
      "Epoch 5/5, Train Loss: 55839717816.5581, Val Loss: 56481397148.7752\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        # Check for NaN in predictions\n",
    "        if torch.isnan(predictions).any():\n",
    "            print(f\"NaN detected in predictions at epoch {epoch}\")\n",
    "            break\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        ## was getting exploding gradients problem with this model, needed to do gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        # print(train_loss)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            predictions = model(X_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Save the best model checkpoint\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': best_val_loss\n",
    "        }, checkpoint_path)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{5}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4c24e43-32b9-4865-b827-4b11b8deeae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from epoch 5 with validation loss 56481397148.7752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_262395/3037169124.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    }
   ],
   "source": [
    "# Load the best checkpoint\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "print(f\"Loaded model from epoch {checkpoint['epoch']+1} with validation loss {checkpoint['val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab97e49-f54f-4968-aae9-8bb41ba0873d",
   "metadata": {},
   "source": [
    "#### Now, let's do the device comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31542258-dc4d-4f51-ba4f-f2095b1ce0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2ba9d01-f196-43df-81a0-2fb4f17bd58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_on_device(model, data_loader, intended_device, epochs=5):\n",
    "    \"\"\"\n",
    "    Trains the model on the specified device and returns the training time.\n",
    "    \"\"\"\n",
    "    device = torch.device(intended_device)\n",
    "    model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(X_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    return training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5f2c4e5-ed4a-4beb-99f0-31a1288bd2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU...\n",
      "Epoch 1/5, Loss: 55966046720.0000\n",
      "Epoch 2/5, Loss: 55951157505.9845\n",
      "Epoch 3/5, Loss: 55925250532.2171\n",
      "Epoch 4/5, Loss: 55887620846.1395\n",
      "Epoch 5/5, Loss: 55838235429.7054\n",
      "CPU Training Time: 2.25 seconds\n",
      "\n",
      "Training on GPU...\n",
      "Epoch 1/5, Loss: 55966105639.6899\n",
      "Epoch 2/5, Loss: 55951226864.1240\n",
      "Epoch 3/5, Loss: 55925403425.7364\n",
      "Epoch 4/5, Loss: 55888340845.1473\n",
      "Epoch 5/5, Loss: 55839482848.2481\n",
      "GPU Training Time: 7.15 seconds\n",
      "\n",
      "GPU is approximately 0.31x faster than CPU.\n"
     ]
    }
   ],
   "source": [
    "input_dim = X.shape[1]\n",
    "model_cpu = SimpleModel(input_dim)\n",
    "model_gpu = SimpleModel(input_dim)\n",
    "\n",
    "# Train on CPU\n",
    "print(\"Training on CPU...\")\n",
    "cpu_time = train_model_on_device(model_cpu, train_loader, intended_device=\"cpu\")\n",
    "print(f\"CPU Training Time: {cpu_time:.2f} seconds\")\n",
    "\n",
    "# Train on GPU (if available)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\nTraining on GPU...\")\n",
    "    gpu_time = train_model_on_device(model_gpu, train_loader, intended_device=\"cuda\")\n",
    "    print(f\"GPU Training Time: {gpu_time:.2f} seconds\")\n",
    "\n",
    "    # Compare CPU and GPU times\n",
    "    speedup = cpu_time / gpu_time\n",
    "    print(f\"\\nGPU is approximately {speedup:.2f}x faster than CPU.\")\n",
    "else:\n",
    "    print(\"\\nGPU not available. Skipping GPU comparison.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde743e1-f835-49cd-950f-ca67aaae79e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62854f50-9a4a-45c9-aab0-4e0e63be32e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
