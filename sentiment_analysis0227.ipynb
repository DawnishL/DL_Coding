{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use some Huggingface libraries for downloading and processing the dataset, and therefore need to install them first.\\\n",
    "The first is the datasets library which allows you to download and manipulate datasets.\\\n",
    "See [their guide](https://huggingface.co/docs/datasets/installation) for an introduction to the datasets library if you want to know more.\\\n",
    "The other library helps us in downloading data from the Huggingface Hub.\n",
    "\n",
    "We can simple install them using pip:\n",
    "> Note that `%pip` is a magic command for use in Jupyter Notebooks as discussed in the tutorial on setting up Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: huggingface_hub in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (0.27.1)\n",
      "Requirement already satisfied: ipywidgets in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: filelock in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: packaging in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: colorama in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in e:\\uni stuttgart\\课程\\intro to dl\\my_env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets huggingface_hub ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Sentiment Analysis (SA) determines the emotional tone of a text sequence (e.g., a sentence) and classifies it into predefined categories.\\\n",
    "Therefore, **SA is a text classification task which assigns a single class to the whole input**.\n",
    "\n",
    "In this part, we will use the SST2 dataset, which stands for Stanford Sentiment Treebank.\\\n",
    "This is a binary task where inputs are labeled as `positive` (`1`) or `negative` (`0`).\n",
    "\n",
    "There are several possibilites on how to 'solve' this task.\\\n",
    "Starting from sequences, there exist many ways to turn them into features.\\\n",
    "A common way is to split them into smaller units, called tokens, which could be words.\\\n",
    "For this, there are again many possibilities how this can be implemented.\\\n",
    "You can do it manually or use some library for it, and there are many NLP libraries.\\\n",
    "Also, the neural network architecture can be almost arbitrary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "\n",
    "There are several possibiliites for downloading datasets.\\\n",
    "You can read them from files, or directly use a library with an online repository of datasets, such as [Huggingface Datasets](https://huggingface.co/docs/datasets/index).\n",
    "\n",
    "> A note on the Huggingface Datasets library: You can decide where downloaded files are cached, see https://huggingface.co/docs/datasets/v3.2.0/en/cache#cache-directory.\\\n",
    "> The documentation is as always a good source of information!\n",
    "\n",
    "We will use this library in our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['idx', 'sentence', 'label'],\n",
      "        num_rows: 67349\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['idx', 'sentence', 'label'],\n",
      "        num_rows: 872\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['idx', 'sentence', 'label'],\n",
      "        num_rows: 1821\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 这行代码是使用Hugging Face的datasets库来加载Stanford Sentiment Treebank v2 (SST-2)数据集。\n",
    "# load_dataset() 是Hugging Face datasets库中的一个函数，用于加载预定义的数据集\n",
    "# SST-2是一个用于情感分析的数据集，包含电影评论片段及其对应的情感标签（正面或负面）。这个数据集通常用于训练和评估情感分类模型。\n",
    "sst2 = load_dataset(\"stanfordnlp/sst2\")\n",
    "# Print the dataset object to see the dataset's structure\n",
    "# features指的是数据集中每个样本包含的特征或属性\n",
    "print(sst2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to learn more about using this library, there is a very useful [tutorial](https://huggingface.co/docs/datasets/v3.2.0/en/tutorial) available online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are three splits, and how many samples are contained in each split.\\\n",
    "Let's take a look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 0, 'sentence': 'hide new secretions from the parental units ', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "dataset_train = sst2[\"train\"]\n",
    "# Print the first sample in the training dataset\n",
    "print(dataset_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, each sample includes an index, the input sentence and a label.\\\n",
    "This sample was labeled `negative` (`0`; `1` stand for `positive` in this dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "In order to turn words into features, we can use pre-trained embeddings.\\\n",
    "These have been trained to carry the semantics of the words.\\\n",
    "See https://nlp.stanford.edu/projects/glove/ for more information.\n",
    "\n",
    "GloVe embeddings exist trained on different data (varying in the number of tokens and vocabulary size), and with different embedding dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glove.6B.100d.txt', 'glove.6B.200d.txt', 'glove.6B.300d.txt', 'glove.6B.50d.txt']\n"
     ]
    }
   ],
   "source": [
    "# Download the GloVe embeddings\n",
    "glove = hf_hub_download(\"stanfordnlp/glove\", \"glove.6B.zip\")\n",
    "\n",
    "with zipfile.ZipFile(glove, \"r\") as f:\n",
    "    print(f.namelist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we use the smallest vocabulary size with 300-dimensional features (but feel free to experiment with other dimensions!).\\\n",
    "How does the file look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'the 0.04656 0.21318 -0.0074364 -0.45854 -0.035639 0.23643 -0.28836 0.21521 -0.13486 -1.6413 -0.26091 0.032434 0.056621 -0.043296 -0.021672 0.22476 -0.075129 -0.067018 -0.14247 0.038825 -0.18951 0.29977 0.39305 0.17887 -0.17343 -0.21178 0.23617 -0.063681 -0.42318 -0.11661 0.093754 0.17296 -0.33073 0.49112 -0.68995 -0.092462 0.24742 -0.17991 0.097908 0.083118 0.15299 -0.27276 -0.038934 0.54453 0.53737 0.29105 -0.0073514 0.04788 -0.4076 -0.026759 0.17919 0.010977 -0.10963 -0.26395 0.07399 0.26236 -0.1508 0.34623 0.25758 0.11971 -0.037135 -0.071593 0.43898 -0.040764 0.016425 -0.4464 0.17197 0.046246 0.058639 0.041499 0.53948 0.52495 0.11361 -0.048315 -0.36385 0.18704 0.092761 -0.11129 -0.42085 0.13992 -0.39338 -0.067945 0.12188 0.16707 0.075169 -0.015529 -0.19499 0.19638 0.053194 0.2517 -0.34845 -0.10638 -0.34692 -0.19024 -0.2004 0.12154 -0.29208 0.023353 -0.11618 -0.35768 0.062304 0.35884 0.02906 0.0073005 0.0049482 -0.15048 -0.12313 0.19337 0.12173 0.44503 0.25147 0.10781 -0.17716 0.038691 0.08153 0.14667 0.063666 0.061332 -0.075569 -0.37724 0.01585 -0.30342 0.28374 -0.042013 -0.040715 -0.15269 0.07498 0.15577 0.10433 0.31393 0.19309 0.19429 0.15185 -0.10192 -0.018785 0.20791 0.13366 0.19038 -0.25558 0.304 -0.01896 0.20147 -0.4211 -0.0075156 -0.27977 -0.19314 0.046204 0.19971 -0.30207 0.25735 0.68107 -0.19409 0.23984 0.22493 0.65224 -0.13561 -0.17383 -0.048209 -0.1186 0.0021588 -0.019525 0.11948 0.19346 -0.4082 -0.082966 0.16626 -0.10601 0.35861 0.16922 0.07259 -0.24803 -0.10024 -0.52491 -0.17745 -0.36647 0.2618 -0.012077 0.08319 -0.21528 0.41045 0.29136 0.30869 0.078864 0.32207 -0.041023 -0.1097 -0.092041 -0.12339 -0.16416 0.35382 -0.082774 0.33171 -0.24738 -0.048928 0.15746 0.18988 -0.026642 0.063315 -0.010673 0.34089 1.4106 0.13417 0.28191 -0.2594 0.055267 -0.052425 -0.25789 0.019127 -0.022084 0.32113 0.068818 0.51207 0.16478 -0.20194 0.29232 0.098575 0.013145 -0.10652 0.1351 -0.045332 0.20697 -0.48425 -0.44706 0.0033305 0.0029264 -0.10975 -0.23325 0.22442 -0.10503 0.12339 0.10978 0.048994 -0.25157 0.40319 0.35318 0.18651 -0.023622 -0.12734 0.11475 0.27359 -0.21866 0.015794 0.81754 -0.023792 -0.85469 -0.16203 0.18076 0.028014 -0.1434 0.0013139 -0.091735 -0.089704 0.11105 -0.16703 0.068377 -0.087388 -0.039789 0.014184 0.21187 0.28579 -0.28797 -0.058996 -0.032436 -0.0047009 -0.17052 -0.034741 -0.11489 0.075093 0.099526 0.048183 -0.073775 -0.41817 0.0041268 0.44414 -0.16062 0.14294 -2.2628 -0.027347 0.81311 0.77417 -0.25639 -0.11576 -0.11982 -0.21363 0.028429 0.27261 0.031026 0.096782 0.0067769 0.14082 -0.013064 -0.29686 -0.079913 0.195 0.031549 0.28506 -0.087461 0.0090611 -0.20989 0.053913\\n'\n",
      "b', -0.25539 -0.25723 0.13169 -0.042688 0.21817 -0.022702 -0.17854 0.10756 0.058936 -1.3854 0.58509 0.036501 -0.19846 0.19613 0.40929 0.15702 -0.15305 0.050447 0.30045 -0.11295 -0.017043 0.18593 0.19982 0.20053 -0.63141 -0.12622 0.2951 -0.26282 -0.15831 0.0012383 0.011784 0.58758 -0.15914 0.27731 -0.82343 -0.21134 0.013414 0.19637 -0.4147 0.0010276 0.13422 -0.14205 0.051545 0.34993 -0.29868 -0.3209 0.19566 0.47886 0.10744 0.010004 0.18503 0.080694 0.20739 -0.097365 -0.039448 0.020151 -0.17378 0.25679 0.24198 -0.351 0.18759 0.0063857 0.18395 -0.13929 0.0081855 -0.63109 0.29832 0.31731 0.13022 -0.32284 -0.050343 -0.114 0.12097 0.14687 -0.33244 -0.055789 -0.05849 0.27551 -0.043855 0.039664 0.15162 -0.086627 0.067729 0.23146 0.015351 -0.15142 -0.031975 0.45181 -0.068806 -0.077058 0.055193 0.054596 -0.24708 0.031113 -0.12826 0.12782 -0.46708 -0.026264 0.010387 -0.33174 0.17277 -0.26894 0.20467 -0.16181 -0.041519 -0.014878 0.10279 0.18868 -0.23396 -0.018436 -0.14747 -0.32685 -0.022055 -0.054 0.16264 0.27095 -0.22792 -0.0077006 0.11206 -0.039787 -0.11906 0.021773 0.05528 -0.13318 -0.056867 0.008304 -0.027021 0.23447 0.086864 0.12009 -0.30726 0.0024735 0.29041 -0.044887 0.12297 0.13077 0.090807 -0.39141 0.080546 0.18724 -0.097481 0.10397 0.11492 0.17775 -0.18167 0.24652 0.20136 -0.23395 -0.35018 -0.14061 0.17091 -0.095465 -0.10962 -0.09836 0.15344 0.08868 -0.22048 -0.13803 -0.11288 -0.08534 0.072735 -0.12732 -0.1964 -0.10586 0.0020616 0.13496 0.058912 -0.043979 -0.091375 0.24408 0.16872 0.24297 -0.43983 0.47089 -0.018595 0.16146 0.19828 -0.17237 -0.0026998 0.52097 -0.080197 0.43324 -0.066261 0.04324 0.084954 -0.14836 -0.41936 0.15988 -0.18411 0.1321 0.27476 0.27279 -0.13465 -0.091238 -0.32523 0.27936 0.023296 -0.33472 0.016878 -0.055544 0.92915 -0.33914 -0.14791 0.017301 0.18272 0.35108 -0.11438 0.13228 -0.021064 -0.27453 -0.10081 -0.046296 0.21689 -0.056319 0.14651 -0.023536 0.068026 -0.045453 -0.23851 -0.33868 0.31396 -0.031914 -0.019217 0.0018715 -0.13328 0.070148 -0.039761 0.070801 0.0018422 -0.12646 0.028675 -0.095728 0.26673 -0.35536 0.15286 0.064565 0.12647 0.23397 -0.046058 0.13519 -0.14549 0.23031 0.42066 0.16267 -0.16541 -0.0020155 0.080653 -0.30025 -0.076014 0.070612 0.3157 0.05352 -0.10721 -0.1366 0.32214 0.2004 0.11609 -0.22501 0.12155 -0.10851 -0.063187 -0.24553 -0.059751 0.068787 -0.11627 -0.0083402 0.0052044 -0.20159 -0.023663 0.17562 -0.31475 -0.11162 -0.12492 0.10949 -0.26913 0.34893 -1.6997 -0.2447 0.30292 0.05672 -0.31737 0.083612 0.095949 -0.1759 0.10235 0.36808 -0.3438 0.20607 0.19135 0.10992 0.075968 -0.014359 -0.073794 0.22176 0.14652 0.56686 0.053307 -0.2329 -0.12226 0.35499\\n'\n",
      "b'. -0.12559 0.01363 0.10306 -0.10123 0.098128 0.13627 -0.10721 0.23697 0.3287 -1.6785 0.22393 0.12409 -0.086708 0.3301 0.34375 -0.00087582 -0.29658 0.24417 -0.11592 -0.035742 -0.01083 0.20776 0.29285 -0.073491 -0.18598 -0.2009 -0.095366 0.0063732 -0.1362 0.092028 -0.039957 0.19027 -0.10456 0.002767 -0.71742 -0.12915 -0.0013451 0.27002 -0.053023 0.22148 0.13881 -0.15051 -0.1915 0.16402 0.097484 0.056841 0.39789 0.40725 0.14802 0.21569 -0.10671 -0.10232 0.02481 -0.221 -0.01072 0.14234 -0.28242 0.19254 0.08672 -0.3897 0.11321 0.0013779 0.0064009 -0.16206 -0.082153 -0.55397 0.36789 -0.0040159 0.2071 -0.37157 0.25135 -0.19544 -0.047059 0.17155 -0.24036 -0.046086 0.19429 -0.18939 -0.0071974 0.069481 0.059175 -0.17585 0.10653 0.16933 -0.036122 0.029911 -0.1183 0.13916 -0.037951 0.1069 -0.26069 -0.10307 -0.12272 -0.15032 -0.042409 0.013354 -0.2851 0.011248 0.16073 -0.16384 0.21233 -0.18476 -0.00090874 0.066687 0.16918 -0.35004 0.099016 0.46393 -0.19462 0.10346 -0.25668 -0.36516 -0.18963 -0.21933 0.024634 0.065627 -0.1112 -0.164 0.010874 -0.084688 -0.14923 -0.070223 0.028887 0.083497 -0.016193 -0.0024926 0.17186 0.0098749 0.080237 0.14774 0.043206 0.27716 0.57697 -0.041297 0.12765 -0.091517 0.14132 0.087579 0.093224 0.015346 -0.19856 0.017277 -0.10708 -0.013059 -0.37227 0.078568 0.16677 -0.15359 -0.33294 0.036986 0.11697 0.039781 0.038464 -0.16247 0.4128 -0.077491 0.04549 0.1133 0.0082177 -0.25052 0.070966 -0.11388 -0.11503 -0.11014 0.10499 0.15878 -0.27023 -0.011006 0.00076057 0.33902 0.25564 0.16342 -0.56019 0.13055 0.076311 -0.028334 0.28721 -0.027844 -0.11561 0.34925 -0.1242 0.21405 0.24116 -0.031343 0.10913 -0.24755 -0.045429 -0.082178 -0.18831 0.18446 -0.097074 0.32395 0.10658 -0.26676 -0.27311 0.017181 0.25796 -0.28048 0.3079 -0.218 0.87415 -0.12297 0.10991 -0.29797 0.13394 0.10615 -0.10789 -0.35976 -0.18311 -0.45133 0.034967 -0.19847 0.21965 0.08152 0.2581 0.040173 0.031394 0.19069 0.0758 -0.060638 0.20739 0.009839 -0.2693 0.066515 -0.10711 0.0059916 0.23284 -0.058663 0.098993 -0.081464 0.067004 -0.14305 0.25506 -0.31971 -0.03107 -0.092451 0.2944 0.28947 -0.059804 0.24286 -0.16755 0.042031 0.51261 0.24525 -0.65983 0.062456 0.052204 -0.025717 -0.080613 0.080869 0.22821 -0.10217 -0.20719 -0.012123 0.34916 0.086527 0.066288 -0.099828 0.25843 0.11943 -0.13667 -0.43962 0.23704 0.031296 0.074701 -0.22387 0.0078162 -0.19016 0.044444 0.20191 -0.20814 -0.28382 0.10427 -0.21098 0.18865 0.31659 -2.0753 -0.071045 0.52419 0.056023 -0.25295 -0.062168 -0.10989 -0.35755 -0.079244 0.37472 -0.28353 0.16337 0.11165 -0.098002 0.060148 -0.15619 -0.11949 0.23445 0.081367 0.24618 -0.15242 -0.34224 -0.022394 0.13684\\n'\n",
      "b'of -0.076947 -0.021211 0.21271 -0.72232 -0.13988 -0.12234 -0.17521 0.12137 -0.070866 -1.5721 -0.22464 0.04269 -0.4018 0.21006 0.014288 0.41628 0.017165 0.071732 0.0069246 0.18107 -0.15412 0.14933 -0.030493 0.29918 0.029479 -0.036147 -0.061125 0.083918 -0.12398 -0.10077 -0.0054142 0.3371 -0.25612 0.44388 -0.68922 0.1802 0.34898 -0.052284 -0.26226 -0.47109 0.21647 -0.4002 -0.049986 0.011376 0.54994 -0.22791 0.095873 0.47693 -0.056727 -0.17895 0.11756 0.14662 0.048948 0.13587 -0.093821 0.45968 -0.32062 0.29911 0.20656 -0.18503 -0.2769 -0.022545 0.70698 -0.23815 0.16437 -0.55044 -0.0010615 0.12266 0.11898 0.23985 0.29815 0.013207 0.16316 -0.61334 -0.37051 0.19444 -0.13621 -0.30426 -0.37715 0.065299 -0.15995 -0.56516 0.074696 0.40184 0.19328 0.041802 0.20572 0.28971 0.34783 0.33873 -0.10052 -0.16397 -0.15236 -0.086815 0.36522 0.14969 -0.40859 0.23106 0.17162 -0.60545 0.086019 0.37043 0.17937 -0.40282 -0.62471 -0.055919 0.15092 0.12554 -0.45344 0.34417 0.40042 -0.049512 -0.29969 -0.31761 0.30023 0.090029 0.3106 -0.033077 -0.21995 -0.40396 -0.34443 -0.21248 -0.37636 0.21835 -0.1785 -0.17261 0.16391 0.22753 0.2686 0.57541 -0.14912 0.20413 0.22187 -0.27014 0.068253 0.29115 -0.067943 0.10623 -0.16281 0.19939 -0.48613 0.035688 -0.12373 0.13707 0.33359 -0.12713 -0.31711 -0.13962 -0.04288 -0.0014614 0.76883 -0.41705 -0.092911 0.16315 0.29202 0.12119 -0.076683 0.14131 -0.093406 -0.042796 0.13738 0.014278 0.11918 -0.34215 -0.19076 -0.12499 0.24648 0.42259 0.091966 0.45351 0.14437 0.1878 -0.85876 0.059621 -0.32242 0.28627 0.12427 0.0090984 -0.1891 0.16638 0.099881 -0.048553 -0.026257 0.099904 0.12406 -0.015416 -0.29707 -0.4044 -0.17258 0.36468 -0.014118 -0.11889 -0.11686 -0.14124 0.28012 0.067644 0.1485 -0.35702 0.29626 0.36004 1.019 -0.067307 -0.11588 -0.2178 0.070191 0.23154 -0.13849 0.26441 0.28742 0.1941 -0.0060504 0.44105 0.12416 -0.27745 -0.25729 0.10992 0.18362 -0.34522 -0.21861 -0.18825 -0.037454 -0.20862 -0.25216 0.060842 0.068595 0.10275 0.10745 -0.061288 0.19725 -0.27739 -0.022559 0.052794 -0.24083 0.09199 0.30959 0.054999 0.063676 -0.087357 -0.34495 0.22793 -0.42405 0.24536 0.55708 0.19126 -0.797 -0.2048 0.32545 0.09235 0.084791 -0.16433 -0.066568 -0.099249 0.31526 -0.44465 0.087281 0.3288 -0.017809 -0.23855 -0.12848 0.041509 0.46728 0.48214 0.10548 0.065805 0.067221 0.13321 -0.27856 0.015532 0.30026 0.38748 -0.14401 -0.16131 0.17678 0.16448 -0.3244 0.007937 -2.2836 0.096945 0.66131 0.16857 -0.028877 -0.10791 -0.027445 -0.25695 0.046686 0.23087 -0.076458 0.27127 0.25185 0.054947 -0.36673 -0.38603 0.3029 0.015747 0.34036 0.47841 0.068617 0.18351 -0.29183 -0.046533\\n'\n",
      "b'to -0.25756 -0.057132 -0.6719 -0.38082 -0.36421 -0.082155 -0.010955 -0.082047 0.46056 -1.8477 -0.11258 -0.12955 0.27254 0.0072891 0.26038 0.12096 -0.23193 0.03226 -0.29472 -0.67594 -0.33844 -0.23297 0.1102 0.18816 -0.45184 -0.33833 0.11274 0.4949 -0.042132 0.079961 -0.013146 0.062284 0.20223 0.038279 -1.1154 -0.1214 0.089846 0.29702 -0.055794 -0.46021 -0.13194 0.087357 -0.27865 0.14981 0.25536 0.16698 -0.04452 0.067588 -0.11772 -0.13452 0.28694 -0.39844 -0.12806 -0.47818 0.067802 0.20353 -0.30677 0.60789 -0.18588 0.11997 -0.040508 -0.06586 0.30621 -0.055824 0.039448 -0.4557 0.21081 0.25889 0.14666 0.3095 0.14343 0.10524 0.15788 0.103 0.32211 -0.27939 -0.17139 0.32202 0.10784 -0.28209 0.12611 -0.23913 -0.089638 -0.39179 -0.26402 0.36796 -0.23691 0.62503 -0.027226 -0.038851 -0.37359 0.045442 -0.17169 -0.54477 -0.091772 -0.32952 -0.25522 0.087106 0.048685 -0.31684 -0.064198 0.044885 -0.49587 0.429 0.36198 -0.14682 0.20122 -0.030038 0.18736 0.31626 0.059023 -0.13473 -0.40664 -0.52983 0.072459 0.082531 -0.32495 -0.006691 0.43564 -0.12976 -0.26293 0.15975 0.25062 -0.064732 -0.30689 0.16084 0.4583 0.38565 0.12612 -0.00080485 0.18055 0.24757 0.5568 0.21701 0.33105 0.11991 0.0027257 -0.10679 -0.16922 0.25277 0.36024 -0.4762 -0.20035 0.38473 -0.71653 -0.13788 -0.12201 -0.16979 -0.29624 -0.010344 0.19216 0.063375 0.30977 -0.19759 0.57419 0.34018 -0.34795 -0.085304 -0.028243 -0.39182 0.23797 -0.092997 0.11981 -0.2368 0.098179 0.083047 0.12652 0.16026 -0.14166 0.14296 -0.12868 0.18181 -0.42337 0.18061 -0.051635 -0.17987 -0.097071 0.0013755 -0.42539 0.56817 0.057432 0.31577 0.18918 0.27639 -0.39906 0.18594 -0.54231 0.61376 0.37921 0.1366 -0.39842 0.58557 0.054558 0.061801 0.32546 -0.19615 -0.034329 -0.013225 0.67854 -0.16672 0.92439 0.11952 0.040351 0.35368 -0.25573 0.26648 -0.020954 0.18535 0.062376 -0.22976 -0.074563 -0.3289 0.28535 0.46959 -0.54324 0.14124 0.19964 0.1541 0.024155 0.144 0.30989 -0.15989 -0.11611 0.09102 -0.50317 -0.33662 0.059168 0.43838 -0.1428 -0.0053718 0.046505 0.21546 0.065006 -0.35175 -0.17137 0.20467 -0.07173 0.40879 0.20295 -0.014211 -0.21898 -0.12831 0.3224 0.17608 -0.60267 0.036737 0.54848 -0.47682 -0.56556 -0.083633 0.032302 -0.25262 0.39481 -0.019623 0.62547 -0.11369 -0.25727 0.073363 0.18437 0.14587 0.32708 -0.52049 0.037555 0.023667 -0.068237 -0.22916 0.017755 -0.18394 0.55107 -0.23965 0.39187 -0.017785 0.43113 0.27181 -0.16043 -0.347 -2.4194 -0.028952 0.95085 0.05804 -0.23623 0.18914 0.31192 0.23064 -0.30309 -0.18603 0.07618 0.37337 -0.14444 -0.028793 -0.012806 -0.59707 0.31734 -0.25267 0.54384 0.063007 -0.049795 -0.16043 0.046744 -0.070621\\n'\n",
      "b'and 0.038466 -0.039792 0.082747 -0.38923 -0.21431 0.1702 -0.025657 0.09578 0.2386 -1.6342 0.14332 -0.037958 -0.019583 0.38494 0.097319 0.29697 -0.34523 0.11742 -0.024189 0.16013 0.09824 0.12811 -0.17482 0.20976 -0.22362 -0.20656 0.24428 0.066875 -0.12594 -0.015706 0.064986 0.4754 -0.055405 0.54286 -0.75188 -0.083218 0.17896 0.073084 -0.3033 -0.17416 -0.17147 -0.1192 0.038308 -0.2066 0.088679 -0.055993 0.361 0.38658 -0.055434 0.097699 0.3686 -0.326 0.13023 -0.29897 -0.24709 0.051869 0.030422 0.18586 -0.046117 -0.14765 0.35895 0.10094 -0.087822 -0.17514 -0.25403 -0.35855 0.15801 -0.027074 0.12565 -0.17509 -0.13126 -0.13916 0.053628 -0.049429 0.051938 -0.048684 0.071719 0.080952 -0.20018 -0.10871 -0.26707 -0.35727 0.3712 0.016709 -0.034959 -0.047711 0.0024827 0.10847 0.0089053 -0.14874 0.046014 0.42702 -0.24684 0.12193 -0.27579 0.25844 -0.20991 -0.086667 0.14767 -0.17441 0.17054 -0.30868 -0.08797 -0.17195 -0.11743 0.12146 0.069268 0.13311 -0.13565 -0.24855 -0.0026393 -0.71169 -0.32594 -0.36397 0.053331 0.35714 -0.30035 0.041583 -0.11996 -0.02368 0.016728 0.15869 -0.16491 -0.2782 -0.13788 0.10178 -0.24177 0.096347 0.2367 0.20885 -0.28867 0.10772 0.15562 -0.012284 -0.22161 -0.1017 0.1257 -0.29579 -0.0089604 0.35075 0.020088 0.020389 0.0038884 0.31869 -0.19848 0.060458 0.28148 -0.23499 -0.17035 -0.22323 0.57975 0.26464 -0.10124 0.081058 0.14029 0.066431 -0.12212 0.040034 0.027548 -0.1476 0.31438 -0.23046 0.2645 -0.10945 -0.39033 0.1266 -0.030951 0.067389 0.16807 0.22373 0.13502 0.38235 -0.52807 0.54013 -0.043062 0.093211 0.045211 -0.24291 -0.49781 0.26425 0.0264 0.14347 0.11763 -0.011614 0.097932 -0.26632 -0.22143 0.25156 0.08128 0.10937 -0.12199 0.019255 -0.33463 -0.18181 0.064724 0.22921 -0.032425 -0.27295 0.31983 0.16134 0.93692 -0.1214 -0.012617 0.25274 0.24615 0.13214 0.16092 0.20576 -0.051567 -0.3784 0.19761 0.16993 -0.087151 0.026922 0.38035 0.083349 0.24715 -0.1094 0.15459 -0.051741 0.16604 -0.21335 -0.030744 -0.14574 -0.50462 0.34825 -0.12343 0.17733 0.2857 -0.30467 -0.15095 0.30346 -0.15678 0.064804 -0.073008 0.26499 0.16312 0.11889 -0.63938 0.15598 -0.23643 0.59644 0.38748 0.3358 -0.58647 0.12584 0.36144 -0.33622 0.38128 -0.10348 0.18825 -0.33686 0.0058178 -0.1345 0.55511 -0.056443 0.15094 -0.28438 0.025488 0.20392 0.052712 -0.45719 0.089267 0.095469 -0.19022 -0.17101 -0.37599 -0.182 -0.065605 -0.061388 -0.19467 -0.070368 -0.23977 0.39253 -0.21283 0.17221 -1.867 -0.22609 0.53976 -0.3358 -0.48587 -0.050246 0.31694 -0.15536 0.12244 0.38356 -0.1389 0.41886 0.23664 -0.31113 0.045194 -0.20405 -0.21097 -0.11025 0.021766 0.44129 0.32797 -0.33427 0.011807 0.059703\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'enumerate()允许我们在遍历可迭代对象（如文件行）时，同时获取每个元素的索引和值。\\n在这个例子中，我们需要知道当前处理的是第几行（索引），以及该行的内容。'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are multiple files with different dimensionality of the features in the zip archive: 50d, 100d, 200d, 300d\n",
    "# 这段代码的主要目的是查看GloVe词向量文件的前几行内容，以了解文件的格式和数据结构。\n",
    "# 通常，GloVe文件的每一行包含一个词及其对应的向量表示。\n",
    "# \"6B\"表示这是基于60亿个词训练的，\"300d\"表示每个词向量的维度是300。\n",
    "filename = \"glove.6B.300d.txt\"\n",
    "# 这行打开了一个ZIP文件。glove应该是一个包含GloVe词向量文件的ZIP文件路径。\n",
    "with zipfile.ZipFile(glove, \"r\") as f:\n",
    "    # 这个循环遍历ZIP文件中指定文件的每一行。enumerate()函数用于同时获取行索引和行内容。\n",
    "    for idx, line in enumerate(f.open(filename)):\n",
    "        print(line)\n",
    "        # 当读取到第6行（索引为5）时，跳出循环。这意味着代码只会打印文件的前6行。\n",
    "        if idx == 5:\n",
    "            break\n",
    "'''enumerate()允许我们在遍历可迭代对象（如文件行）时，同时获取每个元素的索引和值。\n",
    "在这个例子中，我们需要知道当前处理的是第几行（索引），以及该行的内容。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'这种处理方式非常有用，因为：\\n\\n1. 它允许我们通过索引快速查找单词的嵌入向量。\\n2. 它创建了一个可以直接用于深度学习模型的预训练嵌入矩阵。\\n3. word_to_index字典可以用于将文本数据转换为模型可以处理的数字索引。'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpack the downloaded file\n",
    "# 这段代码是用来处理GloVe词向量文件并创建词汇表和嵌入矩阵的。\n",
    "# 创建一个空字典，用于存储单词到索引的映射。\n",
    "word_to_index = dict()\n",
    "# 创建一个空列表，用于存储每个单词的嵌入向量。\n",
    "embeddings = []\n",
    "\n",
    "with zipfile.ZipFile(glove, \"r\") as f:\n",
    "    for idx, line in enumerate(f.open(filename)):\n",
    "        # 将每行分割成单词和向量值。\n",
    "        values = line.split()\n",
    "        # 提取并解码单词（第一个元素）。\n",
    "        word = values[0].decode(\"utf-8\")\n",
    "        # 将剩余的值转换为浮点数，然后创建一个PyTorch张量。\n",
    "        features = torch.tensor([float(value) for value in values[1:]])\n",
    "        # 将单词和其索引添加到字典中。\n",
    "        word_to_index[word] = idx\n",
    "        # 将单词的嵌入向量添加到嵌入列表中。\n",
    "        embeddings.append(features)\n",
    "'''这种处理方式非常有用，因为：\n",
    "\n",
    "1. 它允许我们通过索引快速查找单词的嵌入向量。\n",
    "2. 它创建了一个可以直接用于深度学习模型的预训练嵌入矩阵。\n",
    "3. word_to_index字典可以用于将文本数据转换为模型可以处理的数字索引。'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "Play around and inspect the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the vocabulary: 400001\n",
      "Embedding dimensionality: 300\n",
      "First word in the vocabulary: the\n",
      "Last word in the vocabulary: <unk>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of words in the vocabulary: {len(word_to_index)}\")\n",
    "# embeddings[0]: 这是获取列表中的第一个元素，也就是第一个单词的嵌入向量。我们使用第一个向量是因为所有向量的维度应该是相同的。\n",
    "# .shape: 这是PyTorch张量（tensor）的一个属性，返回张量的形状。\n",
    "# 对于一维张量（向量），shape是一个只包含一个元素的元组，这个元素就是向量的长度。\n",
    "print(f\"Embedding dimensionality: {embeddings[0].shape[0]}\")\n",
    "\n",
    "# Create a reverse mapping from index to word to easily retrieve words from their indices (the line numbers in the file)\n",
    "# .items() 方法返回一个可以遍历的视图对象，包含字典中的所有键值对。\n",
    "index_to_word = {idx: word for word, idx in word_to_index.items()}\n",
    "\n",
    "print(f\"First word in the vocabulary: {index_to_word[0]}\")\n",
    "print(f\"Last word in the vocabulary: {index_to_word[len(index_to_word) - 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We bring the embeddings into a useful format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: 300\n"
     ]
    }
   ],
   "source": [
    "# Last token in the vocabulary is '<unk>' which is used for out-of-vocabulary words\n",
    "# We also add a '<pad>' token to the vocabulary for padding sequences\n",
    "# 它的索引被设置为当前词汇表的长度，也就是说，它会成为词汇表中的最后一个词。\n",
    "word_to_index[\"<pad>\"] = len(word_to_index)\n",
    "# 这行代码获取 <pad> 标记的索引，并将其存储在 padding_token_id 变量中。\n",
    "padding_token_id = word_to_index[\"<pad>\"]\n",
    "# 这行代码获取 <unk> (unknown) 标记的索引，并将其存储在 unk_token_id 变量中。\n",
    "unk_token_id = word_to_index[\"<unk>\"]\n",
    "# 这行代码为 <pad> 标记创建一个全零的嵌入向量，并将其添加到 embeddings 列表中。这个向量的维度与其他嵌入向量相同。\n",
    "# 这创建了一个新的张量，其形状与第一个嵌入向量相同，但所有元素都被初始化为0。\n",
    "# 例如，如果原始嵌入是300维的，这将创建一个300维的全零向量。\n",
    "embeddings.append(torch.zeros(embeddings[0].shape))\n",
    "\n",
    "# Convert the list of tensors to a single tensor\n",
    "# torch.stack() 函数将 embeddings 列表中的所有张量堆叠成一个新的张量\n",
    "'''embeddings（输入）： 这是一个 Python 列表，包含多个 PyTorch 张量。每个张量代表一个词的嵌入向量。\n",
    "例如，如果我们有 10,000 个词，每个词的嵌入是 300 维的，那么 embeddings 就是一个包含 10,000 个形状为 (300,) 的张量的列表。'''\n",
    "# 这个操作将所有的嵌入向量堆叠成一个新的二维张量，并将结果赋值回 embeddings 变量。\n",
    "embeddings = torch.stack(embeddings)\n",
    "# 是一个 PyTorch 操作，用于获取张量 embeddings 的第二个维度的大小，即每个词嵌入向量的维度；size(0) 会返回词汇表的大小（即词的数量）\n",
    "# 这个维度信息对于设置后续的神经网络层很重要，特别是在设置嵌入层或者全连接层的输入维度时。\n",
    "print(f\"Embedding shape: {embeddings.size(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Starting from our input sentences, we need to 1) tokenize the sentences to get smaller units (words or tokens) and 2) convert these tokens into vector representations using the pre-trained embeddings.\n",
    "\n",
    "The datasets library provides support for processing datasets, for more information see https://huggingface.co/docs/datasets/process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 0, 'sentence': 'hide new secretions from the parental units ', 'label': 0, 'token_ids': [5708, 50, 52776, 25, 0, 13054, 1503]}\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text: str):\n",
    "    return text.lower().split()\n",
    "\n",
    "\n",
    "def map_token_to_index(token):\n",
    "    # Return the index of the token or the index of the '<unk>' token if the token is not in the vocabulary\n",
    "    # 如果 token 在字典中，返回其对应的索引；如果 token 不在字典中，返回 unk_token_id（未知标记的索引）\n",
    "    return word_to_index.get(token, unk_token_id)\n",
    "\n",
    "\n",
    "def map_text_to_indices(text: str):\n",
    "    return [map_token_to_index(token) for token in tokenize(text)]\n",
    "\n",
    "\n",
    "def prepare_dataset(dataset):\n",
    "    # dataset.map(...):对数据集中的每个元素应用一个函数；map 方法通常用于转换数据集中的每个项目\n",
    "    # lambda 参数: 表达式\n",
    "    # lambda x: {...}:这是一个匿名函数（lambda函数）它接受一个参数 x，这个 x 代表数据集中的一个项目\n",
    "    # x 是一个字典，包含了该项目的各种属性\n",
    "    '''lambda 函数会这样处理它：\n",
    "        1. 提取 x[\"sentence\"]（\"This is a sample sentence.\"）\n",
    "        2. 将这个句子传递给 map_text_to_indices 函数\n",
    "        3. 创建一个新的字典，键为 \"token_ids\"，值为处理后的结果'''\n",
    "    # 返回值： lambda 函数返回一个新的字典;这个新字典会替换或添加到原始项目中\n",
    "    return dataset.map(lambda x: {\"token_ids\": map_text_to_indices(x[\"sentence\"])})\n",
    "\n",
    "\n",
    "dataset_train_tokenized = prepare_dataset(dataset_train)\n",
    "\n",
    "# Print the first sample in the tokenized training dataset\n",
    "print(dataset_train_tokenized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need a dataloader that takes care of batching our data.\\\n",
    "You have seen this before, but this time we need also take care of padding, since the length of the sentences varies in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 66940,   6333,     60,      6,     26,    261,  31221,   5247,      3,\n",
      "          58369,   9070,      2, 400001, 400001, 400001, 400001, 400001, 400001,\n",
      "         400001, 400001],\n",
      "        [    55,  10132,   5348, 400001, 400001, 400001, 400001, 400001, 400001,\n",
      "         400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001,\n",
      "         400001, 400001],\n",
      "        [    14,  12316,    434, 400001, 400001, 400001, 400001, 400001, 400001,\n",
      "         400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001,\n",
      "         400001, 400001],\n",
      "        [    81,    107,    998,  12535,      4,   1716,      0,    319,   1495,\n",
      "             46,   2065,     60,      7,    539,     13,      0,   1698,      2,\n",
      "         400001, 400001],\n",
      "        [  8039,  18080,     17,      7,  16674,  31527,    161,      3,   3742,\n",
      "            268, 400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001,\n",
      "         400001, 400001],\n",
      "        [     4,    134,      0, 400000,    978,   1005,     20,   2041,     20,\n",
      "             54,     30, 400001, 400001, 400001, 400001, 400001, 400001, 400001,\n",
      "         400001, 400001],\n",
      "        [    37, 209615,     65,      5,    151, 400000,     65, 134791,      3,\n",
      "              0,  58149,   1955,     57,  45298, 400001, 400001, 400001, 400001,\n",
      "         400001, 400001],\n",
      "        [  9215,    440,     59,     47,   2720,      5,     56,     59,     47,\n",
      "          20563,      3,   6540,      5,      0,  30761,   1746,      3,     47,\n",
      "          11007,   4483]])\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# 用于对批次数据进行填充处理，因为所有的句子不是一样长\n",
    "# keys_to_pad: 需要填充的键列表，默认是 [\"token_ids\"]。padding_value: 用于填充的值，默认是 -1。\n",
    "def pad_inputs(batch, keys_to_pad=[\"token_ids\"], padding_value=-1):\n",
    "    # Pad keys_to_pad to the maximum length in batch\n",
    "    padded_batch = {}\n",
    "    '''由于默认情况下 keys_to_pad 只包含 \"token_ids\"，所以在默认情况下：\n",
    "    循环只会执行一次\n",
    "    key 的值将会是字符串 \"token_ids\"'''\n",
    "    for key in keys_to_pad:\n",
    "        # Get maximum length in batch\n",
    "        # sample是一个字典，包含一个键为 \"token_ids\" 的项，对应的值是一个列表\n",
    "        max_len = max([len(sample[key]) for sample in batch])\n",
    "        # Pad all samples to the maximum length\n",
    "        # sample[key]: 获取原始数据\n",
    "        # + [padding_value] * (max_len - len(sample[key])): 在原始数据后添加填充值，使其长度达到 max_len\n",
    "        padded_batch[key] = torch.tensor(\n",
    "            [\n",
    "                sample[key] + [padding_value] * (max_len - len(sample[key]))\n",
    "                for sample in batch\n",
    "            ]\n",
    "        )\n",
    "    # Add remaining keys to the batch\n",
    "    # 这行代码遍历批次中第一个样本的所有键。批次是一个列表，每个元素都是一个字典，代表一个样本。\n",
    "    '''这段代码的主要目的是确保批次中所有不需要填充的数据也被正确地转换为张量并包含在最终的 padded_batch 中。\n",
    "    这样，返回的批次数据就包含了所有原始数据，其中需要填充的数据已经被填充到相同长度，\n",
    "    而不需要填充的数据则保持原样，只是被转换成了张量格式。'''\n",
    "    '''如果键不需要填充，这行代码会执行以下操作：\n",
    "        1. 使用列表推导式 [sample[key] for sample in batch] 从批次中的每个样本提取该键的值。\n",
    "        2. 将提取的值列表转换为 PyTorch 张量。\n",
    "        3. 将这个张量存储在 padded_batch 字典中，使用相同的键。'''\n",
    "    for key in batch[0].keys():\n",
    "        if key not in keys_to_pad:\n",
    "            padded_batch[key] = torch.tensor([sample[key] for sample in batch])\n",
    "    return padded_batch\n",
    "\n",
    "\n",
    "# 参数 batch_size：每个批次的样本数，默认为32; 参数 shuffle：是否打乱数据顺序，默认为False。\n",
    "# 这个函数的主要作用是封装了 DataLoader 的创建过程，并设置了自定义的填充行为。\n",
    "def get_dataloader(dataset, batch_size=32, shuffle=False):\n",
    "    # Create a DataLoader for the dataset\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        # 用于处理和组合样本列表以形成小批量的函数\n",
    "        # 使用 partial 函数创建一个新的函数，这个新函数基于 pad_inputs，但预设了 padding_value 参数为 padding_token_id。\n",
    "        # 这意味着当 DataLoader 调用这个函数来创建批次时，它会使用 pad_inputs 来处理可变长度的序列，并用 padding_token_id 进行填充。\n",
    "        # partial允许我们基于一个已有的函数创建一个新的函数，同时预设一些参数；这在很多情况下都非常有用，特别是当你需要多次使用同一个函数，但每次只改变其中的一部分参数时。\n",
    "        # 为什么需要把padding_value设为padding_token_id\n",
    "        # padding_token_id 通常是词汇表中专门为填充保留的一个特殊标记的ID\n",
    "        # 这里的padding_token_id是词汇表中的最后一个ID\n",
    "        collate_fn=partial(pad_inputs, padding_value=padding_token_id),\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "\n",
    "# We select the columns that we want to keep in the dataset\n",
    "# 这行代码使用with_format方法选择了dataset_train_tokenized数据集中的\"token_ids\"和\"label\"两列。\n",
    "# 这样可以确保在后续处理中只使用这两列数据。\n",
    "'''with_format方法是Hugging Face datasets库中的一个功能，用于指定数据集的输出格式。\n",
    "这个方法允许你选择或重新排列数据集中的列，以及设置其他格式选项。'''\n",
    "dataset_train_tokenized = dataset_train_tokenized.with_format(\n",
    "    columns=[\"token_ids\", \"label\"]\n",
    ")\n",
    "# Create a DataLoader for the training dataset\n",
    "# 这里调用了之前定义的get_dataloader函数，为训练数据集创建一个DataLoader。设置了批次大小为8，并启用了数据打乱（shuffle=True）\n",
    "dataloader_train = get_dataloader(dataset_train_tokenized, batch_size=8, shuffle=True)\n",
    "\n",
    "for batch in dataloader_train:\n",
    "    token_ids = batch[\"token_ids\"]\n",
    "    labels = batch[\"label\"]\n",
    "    print(token_ids)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "We will use a simple network here with the pre-trained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Module是PyTorch中所有神经网络模块的基类\n",
    "class SimpleTextClassifier(torch.nn.Module):\n",
    "    # embeddings：预训练的词嵌入矩阵\n",
    "    # hidden_size：隐藏层的大小\n",
    "    # padding_index：填充符号的索引\n",
    "    def __init__(self, embeddings, hidden_size=128, padding_index=-1):\n",
    "        super().__init__()\n",
    "        # 这行代码创建了一个预训练的嵌入层\n",
    "        # torch.nn.Embedding.from_pretrained(): 这是PyTorch中创建预训练嵌入层的方法。\n",
    "        # 它允许你使用已经训练好的词嵌入来初始化Embedding层。\n",
    "        # freeze=True: 这个参数设置为True表示在训练过程中，这些嵌入权重将不会被更新。这通常用于保持预训练嵌入的原始信息，特别是当你认为这些预训练嵌入已经足够好，或者你的训练数据较少时\n",
    "        # padding_idx=padding_index: 这个参数指定了用于填充的索引。在自然语言处理中，我们经常需要将不同长度的序列填充到相同长度。\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(\n",
    "            embeddings, freeze=True, padding_idx=padding_index\n",
    "        )\n",
    "        # 这行代码创建了一个隐藏层\n",
    "        # shape[0] 表示第一个维度，通常是批次大小（batch size）或行数。\n",
    "        # shape[1] 表示第二个维度，在二维张量中，这通常是列数。\n",
    "        # 对于词嵌入矩阵：\n",
    "        #     embeddings.shape[0] 通常表示词汇表的大小（即有多少个不同的词）。\n",
    "        #     embeddings.shape[1] 表示每个词嵌入向量的维度。\n",
    "        self.layer1 = torch.nn.Linear(embeddings.shape[1], hidden_size)\n",
    "        # 这行代码创建了一个输出层\n",
    "        self.output_layer = torch.nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 将输入转换为词嵌入向量\n",
    "        x = self.embedding(x)\n",
    "        # By summing the embeddings of all tokens in the sequence, we get a bag-of-words vector for each sample input\n",
    "        # 对序列中所有词的嵌入进行求和，得到句子表示\n",
    "        '''\n",
    "  [[1,1,1,1], [2,2,2,2], [3,3,3,3]],  # 第一个句子\n",
    "  [[4,4,4,4], [5,5,5,5], [6,6,6,6]]   # 第二个句子\n",
    "  求和后的结果将是：\n",
    "  [6,6,6,6],   # 第一个句子的表示 (1+2+3, 1+2+3, 1+2+3, 1+2+3)\n",
    "  [15,15,15,15] # 第二个句子的表示 (4+5+6, 4+5+6, 4+5+6, 4+5+6)\n",
    "'''\n",
    "        x = torch.sum(x, dim=1)\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate and verify that the model is working (no errors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4960,  0.3375],\n",
      "        [-0.0364,  0.2072]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 这段代码创建了一个 SimpleTextClassifier 模型实例，并使用它对训练数据集的前两个样本进行预测\n",
    "model = SimpleTextClassifier(embeddings, padding_index=padding_token_id)\n",
    "# 从 dataset_train_tokenized 中获取 \"token_ids\" 列的前两个样本\n",
    "# 将这些样本转换为 PyTorch 张量\n",
    "# 将准备好的输入张量传入模型;这会触发模型的 forward 方法，执行前向传播\n",
    "print(model(torch.tensor(dataset_train_tokenized[\"token_ids\"][:2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "How would you use an RNN instead of this simple feed-forward network?\\\n",
    "See https://pytorch.org/docs/stable/nn.html#recurrent-layers for details on how to use RNNs in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN for Sentence Classification](https://www.tensorflow.org/static/text/tutorials/images/bidirectional.png)\\\n",
    "Source: https://www.tensorflow.org/text/tutorials/text_classification_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTextClassifier(torch.nn.Module):\n",
    "    # num_layers: RNN的层数，默认为1\n",
    "    # bidirectional: 是否使用双向RNN，默认为True\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings,\n",
    "        hidden_size=128,\n",
    "        padding_index=-1,\n",
    "        num_layers=1,\n",
    "        bidirectional=True,\n",
    "    ):\n",
    "        # 调用父类 torch.nn.Module 的初始化方法\n",
    "        super().__init__()\n",
    "        # 创建一个嵌入层，使用预训练的嵌入矩阵初始化。freeze=True 表示在训练过程中不更新这些嵌入\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(\n",
    "            embeddings, freeze=True, padding_idx=padding_index\n",
    "        )\n",
    "        # 创建RNN层。输入大小是嵌入维度embeddings.shape[1]，隐藏状态大小是 hidden_size。\n",
    "        # batch_first=True 表示输入的第一个维度是批次大小。\n",
    "        # num_layers=1 设置RNN的层数,默认为1\n",
    "        self.rnn = torch.nn.RNN(\n",
    "            embeddings.shape[1],\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "        # torch.nn.Linear: 这是PyTorch中的线性层类。它实现了 y = xA^T + b 的操作,其中 A 是权重矩阵,b 是偏置向量\n",
    "        # num_layers: RNN的层数；int(bidirectional) + 1: 如果是双向RNN则为2,否则为1；idden_size: 每个RNN单元的隐藏状态大小\n",
    "        # 输出特征数: 2 这表示输出层将产生两个值，分别代表正面和负面情感。\n",
    "        '''将这三个值相乘的原因：\n",
    "            对于每一层（num_layers），我们都有一个隐藏状态。\n",
    "            对于每个方向（单向或双向，由 int(bidirectional) + 1 决定），我们都有一个隐藏状态。\n",
    "            每个隐藏状态的大小都是 hidden_size。\n",
    "           这个计算确保我们考虑了RNN所有层和所有方向的输出，从而正确地设置了线性层的输入大小'''\n",
    "        self.output_layer = torch.nn.Linear(\n",
    "            num_layers * (int(bidirectional) + 1) * hidden_size, 2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        # RNN模型返回两个值，被解包到 all_hidden_states 和 last_hidden_state\n",
    "        # all_hidden_states: 通常是一个张量，包含了所有时间步的隐藏状态\n",
    "        # last_hidden_state: 最后一个时间步的隐藏状态。对于单向RNN，这就是最后的输出；对于双向RNN，这可能包含前向和后向的最后状态。\n",
    "        all_hidden_states, last_hidden_state = self.rnn(x)\n",
    "        # Concatenate the hidden states of all layers and directions\n",
    "        # 这通常意味着 last_hidden_state 可能是一个元组或其他可迭代对象，包含多个张量\n",
    "        # torch.cat(...)PyTorch的concatenate函数，用于沿指定维度连接张量\n",
    "        # dim=-1 指定沿最后一个维度进行连接；在PyTorch中，-1 表示最后一个维度\n",
    "        '''这个操作的含义和用途：\n",
    "            在双向RNN中，last_hidden_state 可能包含前向和后向的最后隐藏状态。\n",
    "            在多层RNN中，它可能包含每一层的最后隐藏状态。\n",
    "            通过连接这些状态，我们得到一个更大的、包含所有信息的表示。'''\n",
    "        hidden_state = torch.cat(list(last_hidden_state), dim=-1)\n",
    "        # hidden_state = torch.cat([tensor for tensor in last_hidden_state], dim=-1)\n",
    "        output = self.output_layer(hidden_state)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4096, -0.1635], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = RNNTextClassifier(embeddings, padding_index=padding_token_id)\n",
    "print(model(torch.tensor(dataset_train_tokenized[\"token_ids\"][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "To assess the performance of our model, we compute a metric that fits for our task.\\\n",
    "For pure classification like SA, this is often the accuracy and optionally also the loss on the provided dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions: torch.tensor, labels: torch.tensor):\n",
    "    # torch.argmax(predictions, dim=1) == labels: This compares the predicted classes with the true labels, creating a boolean tensor.\n",
    "    # torch.sum(...): This sums up the boolean tensor, effectively counting the number of correct predictions.\n",
    "    # .item(): This extracts the single value from the resulting tensor.\n",
    "    # / len(labels): This divides the count of correct predictions by the total number of samples, giving the accuracy as a fraction.\n",
    "    return torch.sum(torch.argmax(predictions, dim=1) == labels).item() / len(labels)\n",
    "\n",
    "# model: 要评估的模型；dataset: 用于评估的数据集；loss_fn: 可选的损失函数\n",
    "def evaluate_model(model, dataset, loss_fn=None):\n",
    "    # Compute the accuracy and optionally the loss of the model on the dataset\n",
    "    # 数据准备：使用get_dataloader函数创建一个批量大小为32的数据加载器\n",
    "    dataloader = get_dataloader(dataset, batch_size=32)\n",
    "    # 存储每个批次的准确率和损失\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    # We don't need to compute gradients for the evaluation\n",
    "    # torch.no_grad() 是 PyTorch 中的一个上下文管理器，用于临时禁用梯度计算；离开上下文时，会恢复之前的梯度计算状态。\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # 获取输入(token_ids)和标签(labels)；使用模型进行预测\n",
    "            # 如果提供了损失函数，计算损失并存储\n",
    "            token_ids = batch[\"token_ids\"]\n",
    "            labels = batch[\"label\"]\n",
    "            predictions = model(token_ids)\n",
    "            if loss_fn:\n",
    "                loss = loss_fn(predictions, labels)\n",
    "                losses.append(loss.item())\n",
    "            accuracies.append(compute_accuracy(predictions, labels))\n",
    "    return sum(accuracies) / len(accuracies), (\n",
    "        (sum(losses) / len(losses)) if loss_fn else None\n",
    "    )\n",
    "'''这个函数的主要目的是在不进行梯度计算的情况下，评估模型在整个数据集上的性能。\n",
    "它返回模型的平均准确率，以及可选的平均损失值。'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to evaluate our model on a separate dataset, we will also have to process this similarly to our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d13bd6bf5a64880a37e64be2878248a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_val = sst2[\"validation\"]\n",
    "dataset_val_tokenized = prepare_dataset(dataset_val)\n",
    "dataset_val_tokenized = dataset_val_tokenized.with_format(\n",
    "    columns=[\"token_ids\", \"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation dataset: 0.49888392857142855\n"
     ]
    }
   ],
   "source": [
    "accuracy, _ = evaluate_model(model, dataset_val_tokenized)\n",
    "print(f\"Accuracy on the validation dataset: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With randomly initialized weights, we expect to end up at ~50% Accuracy (in average)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now having processed the data and instantiated our model, it is time for training.\\\n",
    "Therefore, we need a loss function and an optimizer.\\\n",
    "The rest is just a simple training loop as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [26:25<00:00, 158.57s/it, Train loss: 0.27026688505026053 - Validation acc: 0.8024553571428571]\n"
     ]
    }
   ],
   "source": [
    "losses_train, losses_val = [], []\n",
    "accuracies_train, accuracies_val = [], []\n",
    "\n",
    "# Compute loss and accuracy on the training set\n",
    "accuracy, loss = evaluate_model(model, dataset_train_tokenized, loss_fn)\n",
    "losses_train.append(loss)\n",
    "accuracies_train.append(accuracy)\n",
    "\n",
    "# Compute loss and accuracy on the validation set\n",
    "accuracy, loss = evaluate_model(model, dataset_val_tokenized, loss_fn)\n",
    "losses_val.append(loss)\n",
    "accuracies_val.append(accuracy)\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# A progress bar to visualize the training progress\n",
    "pbar = trange(NUM_EPOCHS)\n",
    "# Training loop\n",
    "for epoch in pbar:\n",
    "    # Do one epoch of training\n",
    "    for batch in dataloader_train:\n",
    "        # Extract the token ids and the labels from the batch\n",
    "        token_ids = batch[\"token_ids\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(token_ids)\n",
    "        loss = loss_fn(predictions, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate the loss and accuracy on the training set\n",
    "    acc_train, loss_train = evaluate_model(model, dataset_train_tokenized, loss_fn)\n",
    "    accuracies_train.append(acc_train)\n",
    "    losses_train.append(loss_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    acc_val, loss_val = evaluate_model(model, dataset_val_tokenized, loss_fn)\n",
    "    accuracies_val.append(acc_val)\n",
    "    losses_val.append(loss_val)\n",
    "    # 这行代码是用来更新进度条（progress bar）的后缀信息的\n",
    "    # set_postfix_str() 是一个方法，用于设置进度条的后缀字符串\n",
    "    pbar.set_postfix_str(\n",
    "        f\"Train loss: {losses_train[-1]} - Validation acc: {accuracies_val[-1]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the loss and accuracy\n",
    "plt.plot(losses_train, color=\"orange\", linestyle=\"-\", label=\"Train loss\")\n",
    "plt.plot(losses_val, color=\"orange\", linestyle=\"--\", label=\"Validation loss\")\n",
    "plt.plot(accuracies_train, color=\"steelblue\", linestyle=\"-\", label=\"Train accuracy\")\n",
    "plt.plot(accuracies_val, color=\"steelblue\", linestyle=\"--\", label=\"Validation accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to perform some interactive testing with our trained model.\\\n",
    "Widgets allow for a simple text interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77fc6a997b349ecace3d72e9b2103a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='This movie is terrible', description='Sentence:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "\n",
    "sentence_widget = widgets.Text(\n",
    "    value=\"This movie is terrible\",\n",
    "    placeholder=\"Type something\",\n",
    "    description=\"Sentence:\",\n",
    "    disabled=False,\n",
    ")\n",
    "display(sentence_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "Now the task is to do a prediction for the provided sentence using our trained model.\n",
    "\n",
    "Some hints:\n",
    "* You need to convert the input sentence to token ids, using the same mapping as for training. Can you re-use something to accomplish this?\n",
    "* Since we only have a single input, we don't need batching nor a dataloader\n",
    "* We don't need the gradients from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class for the sentence 'This movie is great' is: positive\n"
     ]
    }
   ],
   "source": [
    "sentence = sentence_widget.value\n",
    "# 使用 map_text_to_indices 函数将句子转换为词元（token）索引。\n",
    "# 将结果包装成 PyTorch 张量\n",
    "token_ids = torch.tensor([map_text_to_indices(sentence)])\n",
    "with torch.no_grad():\n",
    "    # 将词元索引输入模型，获取预测结果\n",
    "    predictions = model(token_ids)\n",
    "# torch.argmax() 找出预测张量中最大值的索引\n",
    "# .item() 将结果转换为 Python 标量\n",
    "predicted_class = torch.argmax(predictions).item()\n",
    "print(f\"The predicted class for the sentence '{sentence}' is: {'positive' if predicted_class == 1 else 'negative'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
